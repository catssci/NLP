# 한국어 임베딩

### Embedding
자연어를 벡터로 바꾼 결과 또는 일련의 과정 전체
> 단어나 문장 각각을 벡터로 변환하여 벡터공간에 "끼워넣는다. (Embed)" 해서 **Embedding**
- Corpus 의미, 문장 정보 압축
- 사칙 연산 가능 -> 단어/문서 관련도 계산 가능
- 전이학습 (ELMo, BERT, GPT 등)

### 11가지 모델 학습
- 단어 수준 임베딩: NPLM, Word2Vec, FastText, LSA, GloVe, Swivel (6가지)
- 문장 수준 임베딩: LSA, Doc2Vec, LDA, ELMo, BERT (5가지)
